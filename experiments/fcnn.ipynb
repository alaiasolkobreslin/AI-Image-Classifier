{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 (default, Sep  4 2020, 02:22:02) \n",
      "[Clang 10.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensors and add labels\n",
    "\n",
    "real_cats_dir = '../data/aesthetic_6k/cat_aesthetic'\n",
    "generated_cats_dir = '../data/cat_generated_aesthetic'\n",
    "convert_tensor = transforms.ToTensor()\n",
    "\n",
    "def get_images(dir, label):\n",
    "    images = []\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f):\n",
    "            img = Image.open(f)\n",
    "            images.append((convert_tensor(img), label))\n",
    "    return images\n",
    "\n",
    "# label 0 indicates real image\n",
    "real_images = get_images(real_cats_dir, 0)\n",
    "# label 1 indicates AI image\n",
    "generated_images = get_images(generated_cats_dir, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine real and generated for full dataset\n",
    "# Split into training and testing sets\n",
    "\n",
    "full_dataset = real_images + generated_images\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "images, labels = iter(trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "  def __init__(self, input, hiddensize = 100):\n",
    "    super().__init__()  # needed to invoke the properties of the parent class nn.Module\n",
    "    self.in_layer = nn.Linear(input, hiddensize)\n",
    "    self.out_layer = nn.Linear(hiddensize, 10)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.relu(self.in_layer(x))\n",
    "    x = self.out_layer(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, loss: 430.8718\n",
      "epoch: 6, loss: 396.3283\n",
      "epoch: 9, loss: 366.3928\n",
      "epoch: 12, loss: 338.2157\n",
      "epoch: 15, loss: 314.8653\n"
     ]
    }
   ],
   "source": [
    "# images.shape: torch.Size([16, 3, 256, 256])\n",
    "\n",
    "epochs = 15\n",
    "input_size = 3*256*256\n",
    "hidden_size = 100\n",
    "model = FCNN(input_size, hidden_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3) \n",
    "train_mse = []\n",
    "# training iterations\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for itr, (image, label) in enumerate(trainloader):\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        image = image.view(image.shape[0], -1)\n",
    "        # zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        # forward path\n",
    "        y_predicted = model(image)\n",
    "        loss = criterion(y_predicted, label)\n",
    "        running_loss += loss.item()\n",
    "        # backpropagating\n",
    "        loss.backward()\n",
    "        # optimizes the weights\n",
    "        optimizer.step()\n",
    "    train_mse.append(running_loss)\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss: {running_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network is 0.7129\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for itr, (image, label) in enumerate(testloader):\n",
    "        image = image.view(image.shape[0], -1)\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(label.reshape(len(label),)).sum() \n",
    "        total += float(len(label))\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy of Neural Network is {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7351d9c9f6bb9e6beab6a4b96462f975a0411cbffa515e46baf7e578fe674395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
